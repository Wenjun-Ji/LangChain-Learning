{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sparkllm\n",
    "os.environ[\"IFLYTEK_SPARK_APP_ID\"] = \"\"\n",
    "os.environ[\"IFLYTEK_SPARK_API_KEY\"] = \"\"\n",
    "os.environ[\"IFLYTEK_SPARK_API_SECRET\"] = \"\"\n",
    "#　此处参考：https://www.xfyun.cn/doc/spark/Web.html\n",
    "os.environ[\"IFLYTEK_SPARK_API_URL\"] = \"\"\n",
    "os.environ[\"IFLYTEK_SPARK_llm_DOMAIN\"] = \"\"\n",
    "\n",
    "from langchain_community.chat_models import ChatSparkLLM\n",
    "\n",
    "model = ChatSparkLLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们首先直接使用模型。是LangChain “Runnables” 的实例，这意味着它们公开了一个标准接口来与它们进行交互。只需简单地调用模型，我们就可以将消息列表传递给该方法。`ChatModel.invoke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，小明！有什么我可以帮助你的吗？', response_metadata={'token_usage': {'question_tokens': 4, 'prompt_tokens': 4, 'completion_tokens': 10, 'total_tokens': 14}}, id='run-4f71c835-449e-46a3-9333-14bf24509361-0')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"你好，我叫小明\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该模型本身没有任何状态概念。例如，如果您提出后续问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='您好，我是科大讯飞研发的认知智能大模型，我的名字叫讯飞星火认知大模型。我可以和人类进行自然交流，解答问题，高效完成各领域认知智能需求。', response_metadata={'token_usage': {'question_tokens': 3, 'prompt_tokens': 3, 'completion_tokens': 40, 'total_tokens': 43}}, id='run-0e9bcde0-e6b9-4ef9-b7cf-eec0422797c3-0')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"你的名字是什么\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，它没有将之前的对话变成上下文，也无法回答问题。 这带来了糟糕的聊天机器人体验！\n",
    "\n",
    "为了解决这个问题，我们需要将整个对话历史记录传递到模型中。让我们看看这样做时会发生什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你刚才告诉我，你的名字是小刚。', response_metadata={'token_usage': {'question_tokens': 4, 'prompt_tokens': 19, 'completion_tokens': 10, 'total_tokens': 29}}, id='run-875e266f-b657-4dd4-9a56-0765c6510871-0')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"你好，我是小刚\"),\n",
    "        AIMessage(content=\"你好小刚，请问今天我可以帮你做些什么？\"),\n",
    "        HumanMessage(content=\"我的名字是什么？\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 消息历史记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用 Message History 类来包装我们的模型并使其有状态。 这将跟踪模型的输入和输出，并将它们存储在某个数据存储中。 然后，未来的交互将加载这些消息，并将它们作为输入的一部分传递到链中。 让我们看看如何使用它！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，让我们确保安装 langchain-community ，因为我们将使用其中的集成来存储消息历史记录。\n",
    "\n",
    "` ! pip install langchain_community`\n",
    "\n",
    "之后，我们可以导入相关类并设置我们的链，该链包装模型并添加此消息历史记录。这里的一个关键部分是我们传入的函数。此函数应接受并返回 Message History 对象。这用于区分单独的会话，并且在调用新链时应作为配置的一部分传入（我们将展示如何执行此操作）。`get_session_history`,`session_id`,`session_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个包含会话ID (session_id) 的配置对象，并在每次调用 RunnableWithMessageHistory 时传递这个配置对象。这样可以确保在处理每个请求时都能使用正确的会话ID进行会话历史记录的管理。\n",
    "\n",
    "我们可以定义一个配置对象 `config` ，其中包含 `session_id`。然后在每次调用 RunnableWithMessageHistory 时，将这个配置对象传递给它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，小刚！有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"你好我是小刚\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据你之前所说的信息，你的名字是小刚。'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了更清晰的显示对话历史，我们定义一个函数来打印对话历史\n",
    "def pretty_print_store(store):\n",
    "    def print_message(message, indent=0):\n",
    "        prefix = ' ' * indent\n",
    "        if isinstance(message, str):\n",
    "            print(f\"{prefix}{message}\")\n",
    "        elif isinstance(message, dict):\n",
    "            for key, value in message.items():\n",
    "                print(f\"{prefix}{key}:\")\n",
    "                print_message(value, indent + 4)\n",
    "        else:\n",
    "            print(f\"{prefix}{message}\")\n",
    "\n",
    "    for key, history in store.items():\n",
    "        print(f\"Session ID: {key}\")\n",
    "        print(\"Messages:\")\n",
    "        for message in history.messages:\n",
    "            print_message(message, 4)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: abc2\n",
      "Messages:\n",
      "    content='你好我是小刚'\n",
      "    content='你好，小刚！有什么我可以帮助你的吗？' response_metadata={'token_usage': {'question_tokens': 4, 'prompt_tokens': 4, 'completion_tokens': 11, 'total_tokens': 15}} id='run-d7d0501a-b368-4f17-a61b-3c495ccc307e-0'\n",
      "    content='我的名字是什么?'\n",
      "    content='根据你之前所说的信息，你的名字是小刚。' response_metadata={'token_usage': {'question_tokens': 4, 'prompt_tokens': 19, 'completion_tokens': 12, 'total_tokens': 31}} id='run-879ea651-67f8-494a-b1d6-4ee56105cbb8-0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_store(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的聊天机器人现在记住了关于我们的事情。如果我们更改配置以引用不同的 ，我们可以看到它重新开始对话。`session_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很抱歉，我不知道您的名字。请问您可以告诉我您的名字吗？'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: abc2\n",
      "Messages:\n",
      "    content='你好我是小刚'\n",
      "    content='你好，小刚！有什么我可以帮助你的吗？' response_metadata={'token_usage': {'question_tokens': 4, 'prompt_tokens': 4, 'completion_tokens': 11, 'total_tokens': 15}} id='run-d7d0501a-b368-4f17-a61b-3c495ccc307e-0'\n",
      "    content='我的名字是什么?'\n",
      "    content='根据你之前所说的信息，你的名字是小刚。' response_metadata={'token_usage': {'question_tokens': 4, 'prompt_tokens': 19, 'completion_tokens': 12, 'total_tokens': 31}} id='run-879ea651-67f8-494a-b1d6-4ee56105cbb8-0'\n",
      "\n",
      "Session ID: abc3\n",
      "Messages:\n",
      "    content='我的名字是什么'\n",
      "    content='很抱歉，我不知道您的名字。请问您可以告诉我您的名字吗？' response_metadata={'token_usage': {'question_tokens': 3, 'prompt_tokens': 3, 'completion_tokens': 13, 'total_tokens': 16}} id='run-77997f7f-8757-49c2-bca4-f1692ec6dd53-0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_store(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，我们总是可以回到原始对话（因为我们将其保存在store字典中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据前面你所说过的信息，你的名字是小刚。'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示模板有助于将原始用户信息转换为 LLM 可以使用的格式。在这种情况下，原始用户输入只是一条消息，我们将它传递给 LLM。现在让我们让它更复杂一点。首先，让我们添加一个带有一些自定义指令的系统消息（但仍然将消息作为输入）。接下来，除了消息之外，我们还将添加更多输入。\n",
    "\n",
    "首先，让我们添加一条系统消息。为此，我们将创建一个 `ChatPromptTemplate`。我们将利用所有消息传递。`MessagesPlaceholder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ChatPromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html):是一个用于创建和管理聊天提示的模板类。它允许你定义一个模板，其中包含变量占位符，这些占位符可以在实际使用时被动态值替换。这样可以方便地创建复杂的聊天提示，而不需要手动拼接字符串。\n",
    "\n",
    "[MessagePlaceholder](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html)：是一种特殊的占位符，用于在聊天提示模板中插入消息历史记录。它允许你在生成新的聊天提示时，自动包含之前的对话内容，从而保持上下文的连续性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"你是一个有力的帮手，可以尽你所能帮助我。\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，这略微改变了输入类型 - 我们现在不是传入消息列表，而是传入一个带有键的字典，其中包含消息列表。`messages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，鲍勃！很高兴认识你。请问有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"你好，我是鲍勃\")]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们可以将其包装在与以前相同的 Messages History 对象中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，鲍勃！很高兴为你提供帮助。请问有什么我可以帮助你的？'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"你好，我是鲍勃\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你告诉我的，你的名字是鲍勃。'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是谁？\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们的提示稍微复杂一点。让我们假设提示模板现在看起来像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"你是一个有帮助的助手。请用 {language} 回答所有问题，并尽你所能提供帮助。\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，鲍勃！很高兴见到你。有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"你好，我是鲍勃\")], \"language\": \"英语\"}\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们将这个更复杂的链包装在 Message History 类中。这一次，由于输入中有多个键，我们需要指定用于保存聊天记录的正确键。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc11\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola Todd! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm todd\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 管理对话历史记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建聊天机器人时要了解的一个重要概念是如何管理对话历史记录。如果不进行管理，消息列表将无限制增长，并可能溢出 LLM 的上下文窗口。因此，添加一个步骤来限制您传入的消息的大小非常重要。\n",
    "\n",
    "重要的是，您需要在提示模板之前执行此操作，但在从消息历史记录加载以前的消息之后执行此操作。\n",
    "\n",
    "为此，我们可以在提示符前面添加一个简单的步骤来适当地修改密钥，然后将该新链包装在 Message History 类中。messages\n",
    "\n",
    "LangChain带有一些内置的帮助程序，用于管理消息列表。在本例中，我们将使用 trim\n",
    "_messages 帮助程序来减少向模型发送的消息数。修剪器允许我们指定要保留的令牌数量，以及其他参数，例如我们是否要始终保留系统消息以及是否允许部分消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\"),\n",
       " HumanMessage(content='I like vanilla ice cream'),\n",
       " AIMessage(content='nice'),\n",
       " HumanMessage(content='thanks'),\n",
       " AIMessage(content='no problem!'),\n",
       " HumanMessage(content='having fun?'),\n",
       " AIMessage(content='yes!'),\n",
       " HumanMessage(content='please help me with a math problem : what 1+(3*2)-4 is'),\n",
       " AIMessage(content='3')]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.messages.utils import trim_messages\n",
    "\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=60, # 指定修剪后的消息列表中最多包含 60 个令牌。\n",
    "    strategy=\"last\", # 使用 \"last\" 策略，这意味着保留最后的消息，直到达到令牌限制。\n",
    "    token_counter=model, # 指定用于计算消息中令牌数量的函数或模型。这里假设 model 是一个可以计算令牌数量的对象或函数。\n",
    "    include_system=True, # 保留系统消息，即使它不在修剪策略范围内，也会包含在修剪后的消息列表中。\n",
    "    allow_partial=False, # 不允许部分消息，这意味着要么保留整个消息，要么完全删除它。\n",
    "    start_on=\"human\", # 从第一个出现的 HumanMessage 开始修剪。这意味着在修剪过程中，只有在遇到 HumanMessage 之后的消息才会被考虑。\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "    HumanMessage(content=\"please help me with a math problem : what 1+(3*2)-4 is\"),\n",
    "    AIMessage(content=\"3\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API 参考：[SystemMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.system.SystemMessage.html) | [trim_messages](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.utils.trim_messages.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要在我们的链中使用它，我们只需要在将输入传递到提示符之前运行修剪器。messages\n",
    "\n",
    "现在，如果我们尝试向模型询问我们的名字，它不会知道它，因为我们修剪了聊天记录的那部分："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, as an AI language model, I don't have the ability to know your name. Is there anything else I can help you with?\""
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，如果我们询问最后几条消息中的信息，它会记住："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"you're a good assistant\"), HumanMessage(content=\"hi! I'm bob\"), AIMessage(content='hi!'), HumanMessage(content='I like vanilla ice cream'), AIMessage(content='nice'), HumanMessage(content='thanks'), AIMessage(content='no problem!'), HumanMessage(content='having fun?'), AIMessage(content='yes!'), HumanMessage(content='please help me with a math problem : what 1+(3*2)-4 is'), AIMessage(content='3'), HumanMessage(content='what math problem did i ask')]\n"
     ]
    }
   ],
   "source": [
    "print( messages + [HumanMessage(content=\"what math problem did i ask\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'您刚才问了一个数学问题，问题是 \"1+(3*2)-4\" 的结果是多少。'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"我们刚才的对话内容是什么\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们将其包装在消息历史记录中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"abc20\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI language model, I don't have access to your personal information or identity. Is there anything else I can help you with?\""
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不出所料，我们说出我们名字的第一条消息已被修剪。此外，聊天记录中现在还有两条新消息（我们的最新问题和最新回复）。这意味着过去在我们的对话历史记录中可以访问的更多信息不再可用！在本例中，我们最初的数学问题也从历史记录中删减了，因此模型不再知道它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to your previous queries or conversations. Can you please provide me with the math problem you are referring to? I'll do my best to help you solve it.\""
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们有了一个功能聊天机器人。然而，聊天机器人应用程序的一个非常重要的用户体验考虑因素是流媒体。LLM 有时可能需要一段时间才能做出响应，因此为了改善用户体验，大多数应用程序所做的一件事就是在生成每个令牌时流回每个令牌。这允许用户查看进度。\n",
    "\n",
    "这其实非常容易做到！\n",
    "\n",
    "所有链都公开一个方法，使用消息历史记录的链也不例外。我们可以简单地使用该方法来返回流式响应。`.stream`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, Todd! Here's a joke for you:\n",
      "\n",
      "Why did the tomato turn red?\n",
      "Because it saw the salad dressing!|"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc14\"}}\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"hi! I'm todd. tell me a joke\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    print(r.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
